{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-pyser-gans.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "S3YgQaEGGoOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generative Adversial Neural Networks\n",
        "\n",
        "Generative adversarial networks (GANs) are a class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks contesting with each other in a zero-sum game framework. They were introduced by Ian Goodfellow et al. in 2014. This technique can generate photographs that look at least superficially authentic to human observers, having many realistic characteristics (though in tests people can tell real from generated in many cases)\n",
        "\n",
        "https://en.wikipedia.org/wiki/Generative_adversarial_network\n",
        "\n",
        "https://github.com/kroosen/GAN-in-keras-on-mnist/blob/master/GAN-keras-mnist-MLP.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "s8G-lAKw_YtF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255\n",
        "\n",
        "X_train = X_train[60:]\n",
        "Y_train = Y_train[10:]\n",
        "\n",
        "z_dim = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0VMHVqubAcXP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "adam = Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "g = Sequential()\n",
        "g.add(Dense(32, input_dim=z_dim, activation=LeakyReLU(alpha=0.2)))\n",
        "g.add(Dense(64, activation=LeakyReLU(alpha=0.2)))\n",
        "g.add(Dense(128, activation=LeakyReLU(alpha=0.2)))\n",
        "g.add(Dense(784, activation='sigmoid'))  # Values between 0 and 1\n",
        "g.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "d = Sequential()\n",
        "d.add(Dense(128, input_dim=784, activation=LeakyReLU(alpha=0.2)))\n",
        "d.add(Dropout(0.3))\n",
        "d.add(Dense(64, activation=LeakyReLU(alpha=0.2)))\n",
        "d.add(Dropout(0.3))\n",
        "d.add(Dense(32, activation=LeakyReLU(alpha=0.2)))\n",
        "d.add(Dropout(0.3))\n",
        "d.add(Dense(1, activation='sigmoid'))  # Values between 0 and 1\n",
        "d.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "d.trainable = False\n",
        "inputs = Input(shape=(z_dim, ))\n",
        "hidden = g(inputs)\n",
        "output = d(hidden)\n",
        "gan = Model(inputs, output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F0huCOk9AkzQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Set up a vector (dict) to store the losses\n",
        "losses = {\"D\":[], \"G\":[]}\n",
        "\n",
        "def train(epochs=1, plt_frq=1, BATCH_SIZE=128):\n",
        "    batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
        "    print('Epochs:', epochs)\n",
        "    print('Batch size:', BATCH_SIZE)\n",
        "    print('Batches per epoch:', batchCount)\n",
        "    \n",
        "    for e in range(1, epochs+1):\n",
        "        if e == 1 or e%plt_frq == 0:\n",
        "            print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in range(batchCount):  \n",
        "            # Create a batch by drawing random index numbers from the training set\n",
        "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
        "            # Create noise vectors for the generator\n",
        "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
        "            \n",
        "            # Generate the images from the noise\n",
        "            generated_images = g.predict(noise)\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            # Create labels\n",
        "            y = np.zeros(2*BATCH_SIZE)\n",
        "            y[:BATCH_SIZE] = 0.9  # One-sided label smoothing\n",
        "\n",
        "            # Train discriminator on generated images\n",
        "            d.trainable = True\n",
        "            d_loss = d.train_on_batch(X, y)\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
        "            y2 = np.ones(BATCH_SIZE)\n",
        "            d.trainable = False\n",
        "            g_loss = gan.train_on_batch(noise, y2)\n",
        "\n",
        "        # Only store losses from final batch of epoch\n",
        "        losses[\"D\"].append(d_loss)\n",
        "        losses[\"G\"].append(g_loss)\n",
        "\n",
        "        # Update the plots\n",
        "        if e == 1 or e%plt_frq == 0:\n",
        "            plot_generated()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vTe_xVM-Ao4T",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train(epochs=200, plt_frq=1, BATCH_SIZE=32)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}